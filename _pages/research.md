---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
comments: false
---

<!-- YouTube Audit Methods -->
<p style="margin-bottom:-25px; font-size:24px; font-family:Forum; font-weight:bold;">How Audit Methodologies Impact Our Understanding of YouTube’s Recommendation Systems | ICWSM' 24</p>
<p style="margin-bottom:10px; font-size:22px; font-family:Forum">
<strong>Sarmad Chandio</strong>, Daniyal Pirwani, Rishab Nithyanand $~$ 
  <a href="https://ojs.aaai.org/index.php/ICWSM/article/view/31311"><img src="https://raw.githubusercontent.com/FortAwesome/Font-Awesome/6.x/svgs/regular/file-pdf.svg" width="30" height="30" ></a> 
</p> 

Computational audits of social media websites forms basis of our understanding of algorithmic recommendation systems. However, these audits are not always consistent. Focusing on YouTube, we have evidence supporting that it shows left leaning recommendations, contrastingly, we also have evidence showing that it is right leaning. One reason for these conflicting findings is the complexity involved in designing these audits. We demonstrate that conducting sock-puppet audits to make specific inferences about the underlying content recommendation system is more methodologically challenging than one might expect, with slight changes in the audit design leading to drastic changes in the findings.

<br/> <br/> <br/>


<!-- Social Media Radicationzation -->
<p style="margin-bottom:-25px; font-size:24px; font-family:Forum; font-weight:bold;"> The Effect of Using Social Media on Abortion Attitudes | Working</p>
<br/>
What sets social media apart as a news source from traditional media is its tendency to create a filter bubble around one’s opinions. In a longitudinal survey, we collect the opinions of individuals on abortion in two waves, distanced a year apart (2021-2022). We also collect their behavioral data usage during this time frame to receive a complete picture of their consumption pattern. Using both these data sources, we compare the social media histories of users to quantify its influence in swaying user opinions.
<br/> <br/> <br/>


<!-- YouTube Radcialization Properties -->

<!-- Data Voids -->
<p style="margin-bottom:-25px; font-size:24px; font-family:Forum; font-weight:bold;"> Systematically Detecting Data Voids | Working</p>
<br/>
Language is constantly evolving with new terms and expressions, while existing ones take on fresh meanings. Our project focuses on analyzing emerging problematic terms and the subtle ways in which previously neutral language can shift into concerning territory — a phenomenon known as data voids. For example, during the 2021 COVID-19 pandemic, individuals searching for health information might have encountered terms like ‘plandemic,’ which led them to conspiracy theories rather than factual medical resources. We are developing early detection methods for identifying future problematic terms before they can significantly impact online discourse and information seeking behavior.

<br/> <br/> <br/>




<!-- Online Volunteer Moderators -->
<p style="margin-bottom:-25px; font-size:24px; font-family:Forum; font-weight:bold;"> The Effect of Monetary Incentives on the Behavior of Online Content Moderators | Thinking</p>
<br/>
Online _volunteer_ content moderators keep the internet clean. But are they volunteering or being exploited? Focusing on Reddit moderators, this work aims to understand the intrinsic motivation of them volunteering by quantitatively measuring the change in their behavior for different monetray incentives.
<br/> <br/> <br/>


